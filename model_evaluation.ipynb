{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1788d15a-683d-4b36-8ffa-80532f5052fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Crop Recommendation Model Evaluation\n",
      "üåæ Crop Accuracy: 100.00%\n",
      "\n",
      "üß™ Evaluating Fertilizer Recommendation Model...\n",
      "Model expects features: ['N', 'P', 'K', 'temperature', 'humidity', 'rainfall']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Fertilizer Accuracy: 83.25%\n",
      "üåø Evaluating Disease Detection Model (CNN)‚Ä¶\n",
      "Found 12289 images belonging to 39 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARSHINI HOSOKLU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m385/385\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 202ms/step - accuracy: 0.7685 - loss: 2.4317\n",
      "üåø Disease Detection Accuracy: 73.97%\n",
      "üìà Market Dashboard Data Check‚Ä¶\n",
      "\n",
      "‚ñ∂Ô∏è area.csv (first 5 rows):\n",
      "  state_name         district     year commodity_name    area\n",
      "0  Karnataka         BAGALKOT  2001-02       Arecanut     4.0\n",
      "1  Karnataka         BAGALKOT  2003-04       Arecanut     6.0\n",
      "2  Karnataka  BANGALORE RURAL  2001-02       Arecanut  1828.0\n",
      "3  Karnataka  BANGALORE RURAL  2003-04       Arecanut  1998.0\n",
      "4  Karnataka          BELGAUM  2003-04       Arecanut     2.0 \n",
      "\n",
      "‚ñ∂Ô∏è prices.csv (first 5 rows):\n",
      "       commodity_name     market_name arrival_date  modal_price\n",
      "0       Alasande+Gram       Bagalakot   22-05-2019        46.46\n",
      "1       Alasande+Gram       Bangalore   22-05-2019        50.50\n",
      "2       Alasande+Gram      Laxmeshwar   22-05-2019        36.54\n",
      "3            Antawala  Chikkamagalore   22-05-2019        20.00\n",
      "4  Arhar+Dal(Tur+Dal)       Bangalore   22-05-2019        83.00 \n",
      "\n",
      "‚ñ∂Ô∏è production.csv (first 5 rows):\n",
      "  state_name  district  year commodity_name  production\n",
      "0  Karnataka  BAGALKOT  1998      Arhar/Tur      2602.0\n",
      "1  Karnataka  BAGALKOT  1998          Bajra     52375.0\n",
      "2  Karnataka  BAGALKOT  1998    Castor seed        61.0\n",
      "3  Karnataka  BAGALKOT  1998   Cotton(lint)     22129.0\n",
      "4  Karnataka  BAGALKOT  1998      Groundnut      7734.0 \n",
      "\n",
      "‚ñ∂Ô∏è area.csv columns: ['state_name', 'district', 'year', 'commodity_name', 'area']\n",
      "‚ñ∂Ô∏è prices.csv columns: ['commodity_name', 'market_name', 'arrival_date', 'modal_price']\n",
      "‚ñ∂Ô∏è production.csv columns: ['state_name', 'district', 'year', 'commodity_name', 'production'] \n",
      "\n",
      "‚ñ∂Ô∏è modal_price stats:\n",
      " count    26979.000000\n",
      "mean       425.326633\n",
      "std       3700.574167\n",
      "min          0.000000\n",
      "25%         16.000000\n",
      "50%         24.500000\n",
      "75%         47.850000\n",
      "max      66000.000000\n",
      "Name: modal_price, dtype: float64 \n",
      "\n",
      "‚ñ∂Ô∏è Unique commodities: ['Alasande+Gram' 'Antawala' 'Arhar+Dal(Tur+Dal)' 'Avare+Dal' 'Banana'\n",
      " 'Beans' 'Beetroot' 'Black+pepper' 'Bottle+gourd' 'Brinjal' 'Cabbage'\n",
      " 'Capsicum' 'Carrot' 'Cashewnuts' 'Cauliflower' 'Chapparad+Avare'\n",
      " 'Chennangi+Dal' 'Chili+Red' 'Chilly+Capsicum' 'Coconut' 'Copra' 'Cotton'\n",
      " 'Cucumbar(Kheera)' 'Dry+Chillies' 'Elephant+Yam+(Suran)' 'Garlic'\n",
      " 'Ginger(Green)' 'Grapes' 'Green+Chilli' 'Green+Peas' 'Ground+Nut+Seed'\n",
      " 'Groundnut' 'Gur(Jaggery)' 'Jowar(Sorghum)' 'Knool+Khol'\n",
      " 'Kulthi(Horse+Gram)' 'Maize' 'Mango' 'Mango+(Raw-Ripe)' 'Mustard' 'Onion'\n",
      " 'Paddy(Dhan)(Common)' 'Papaya' 'Potato' 'Raddish' 'Ragi+(Finger+Millet)'\n",
      " 'Rice' 'Ridgeguard(Tori)' 'Safflower' 'Soyabean' 'Suvarna+Gadde'\n",
      " 'Tamarind+Fruit' 'Tender+Coconut' 'Tomato' 'Turmeric' 'Wheat'\n",
      " 'Corriander+seed' 'Drumstick' 'Ginger(Dry)' 'Barley+(Jau)' 'Snakeguard'\n",
      " 'Lime' 'Methi(Leaves)' 'Dry+Grapes' 'She+Buffalo' 'Sheep'\n",
      " 'Banana+-+Green' 'Sunflower' 'Bitter+gourd' 'Cowpea(Veg)' 'Goat'\n",
      " 'Methi+Seeds' 'Moath+Dal' 'Coriander(Leaves)' 'Tamarind+Seed' 'Ram'\n",
      " 'Thondekai' 'Honge+seed' 'White+Pumpkin' 'Cow' 'Sweet+Pumpkin'\n",
      " 'Neem+Seed' 'Ox' 'Same/Savi' 'Orange' 'She+Goat' 'Cummin+Seed(Jeera)'\n",
      " 'Alsandikai' 'Niger+Seed+(Ramtil)' 'Thogrikai' 'Sweet+Potato' 'Bull'\n",
      " 'Calf' 'Green+Avare+(W)' 'Leafy+Vegetable' 'Sajje' 'Marigold(Calcutta)'\n",
      " 'Chrysanthemum(Loose)' 'Cotton+Seed' 'Water+Melon' 'Seemebadnekai'\n",
      " 'Mataki' 'Karbuja(Musk+Melon)' 'Lint' 'Gurellu' 'Castor+Seed' 'Pineapple'\n",
      " 'Ashgourd' 'Guava' 'Jack+Fruit' 'Mousambi(Sweet+Lime)' 'Peas+Wet'\n",
      " 'Bunch+Beans' 'Snake+gourd' 'Ridge+gourd(Tori)' 'Duster+Beans'\n",
      " 'Chikoos(Sapota)' 'Pomegranate' 'Apple' 'Rose(Loose)' 'Wood'\n",
      " 'Alasande Gram' 'Arecanut(Betelnut/Supari)' 'Arhar (Tur/Red Gram)(Whole)']\n",
      "‚ñ∂Ô∏è Unique markets: ['Bagalakot' 'Bangalore' 'Laxmeshwar' 'Chikkamagalore'\n",
      " 'Mysore (Bandipalya)' 'Shimoga' 'Channapatana' 'Kolar' 'Ramanagara'\n",
      " 'Honnali' 'Gonikappal' 'Kundapura' 'Arasikere' 'Kadur' 'Kanakapura'\n",
      " 'Tiptur' 'Bijapur' 'Dharwar' 'Raichur' 'Bangarpet' 'Hubli (Amaragol)'\n",
      " 'Sindhanur' 'Hirekerur' 'Davangere' 'Hiriyur' 'Bellary' 'Chitradurga'\n",
      " 'Gadag' 'Mundaragi' 'Savanur' 'Basava Kalayana' 'Mandya' 'Mhalingapur'\n",
      " 'Bidar' 'Manvi' 'Hanagal' 'Kudchi' 'Shikaripura' 'Sorabha' 'Srinivasapur'\n",
      " 'Tarikere' 'Bagepalli' 'Bhadravathi' 'Channagiri' 'Haliyala' 'Harihara'\n",
      " 'Nanjangud' 'Piriya Pattana' 'Gangavathi' 'Nippani' 'Somvarpet'\n",
      " 'K.R. Pet' 'Madhugiri' 'Gowribidanoor' 'Lingasugur' 'Chintamani' 'Hunsur'\n",
      " 'Malur' 'Kumta' 'Annigeri' 'Shorapur' 'Harappana Halli' 'Byadagi'\n",
      " 'Haveri' 'Gulbarga' 'Moodigere' 'Srirangapattana' 'Holalkere' 'Udupi'\n",
      " 'Gundlupet' 'Mulabagilu' 'Sira' 'Santhesargur' 'Turvekere' 'Nargunda'\n",
      " 'Koppal' 'Kottur' 'Rona' 'Belgaum' 'Ramdurga' 'Gubbi' 'Tumkur' 'Yellapur'\n",
      " 'Athani' 'Karatgi' 'Siddapur' 'Kustagi' 'Yadgir' 'Holenarsipura'\n",
      " 'T. Narasipura' 'Karwar' 'Hosadurga' 'Chickkaballapura' 'H.B. Halli'\n",
      " 'Chamaraj Nagar' 'Maddur' 'Badami' 'Karkala' 'Doddaballa Pur'\n",
      " 'Ranebennur' 'Thirthahalli' 'Hosanagar' 'Sirsi' 'K.R.Nagar' 'Hoskote'\n",
      " 'Hoovinahadagali' 'Sakaleshpura' 'Gokak' 'Challakere' 'Kunigal'\n",
      " 'Kalagategi' 'Kollegal' 'Pavagada' 'Bhalki' 'Hungund' 'Pandavapura'\n",
      " 'Sankeshwar' 'Mundgod' 'Chittapur' 'Shiggauv' 'Arakalgud' 'Hospet'\n",
      " 'Jagalur' 'Soundati' 'Sindagi' 'Channarayapatna' 'Koppa' 'Nagamangala'\n",
      " 'Huliyar' 'Bailahongal' 'Binny Mill (F&V) Bangalore' 'Mangalore'\n",
      " 'Bantwala' 'Belthangdi' 'Puttur' 'Sagar' 'Sulya' 'Madikeri' 'Yalburga']\n",
      "\n",
      "‚úÖ Market data looks good! Your Streamlit dashboard should be able to load these files.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Crop Recommendation\n",
    "print(\"üìä Crop Recommendation Model Evaluation\")\n",
    "model_crop = joblib.load(\"../models/crop_rec.pkl\")\n",
    "df_crop   = pd.read_csv(\"../../../data/Crop_recommendation.csv\")\n",
    "X = df_crop.drop(\"label\", axis=1)\n",
    "y = df_crop[\"label\"]\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "acc = accuracy_score(y_test, model_crop.predict(X_test))\n",
    "print(f\"üåæ Crop Accuracy: {acc*100:.2f}%\\n\")\n",
    "\n",
    "\n",
    "# 2. Fertilizer Recommendation\n",
    "# üß™ Fertilizer Recommendation Model Evaluation\n",
    "print(\"üß™ Evaluating Fertilizer Recommendation Model...\")\n",
    "model_fert = joblib.load(\"../models/fert_rec.pkl\")\n",
    "\n",
    "df_fert = pd.read_csv(\"../../../data/data_core.csv\")\n",
    "\n",
    "# 1) Rename to match training names exactly:\n",
    "df_fert = df_fert.rename(columns={\n",
    "    \"Nitrogen\": \"N\",\n",
    "    \"Phosphorous\": \"P\",\n",
    "    \"Potassium\": \"K\",\n",
    "    \"Humidity\": \"humidity\",\n",
    "    \"Moisture\": \"rainfall\",\n",
    "    \"Temparature\": \"temperature\",  # fix spelling\n",
    "    # drop ‚ÄúSoil Type‚Äù or anything not used by model\n",
    "})\n",
    "\n",
    "# 2) Subset to exactly the features the model expects:\n",
    "expected = list(model_fert.feature_names_in_)\n",
    "print(\"Model expects features:\", expected)\n",
    "X = df_fert[expected]  # keeps only these columns, in the correct order\n",
    "\n",
    "# 3) Identify label column:\n",
    "label_col = \"Fertilizer Name\"  # as you discovered before\n",
    "y = df_fert[label_col]\n",
    "\n",
    "# 4) Split & evaluate\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "acc = accuracy_score(y_test, model_fert.predict(X_test))\n",
    "print(f\"üß™ Fertilizer Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Disease Detection (CNN)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(\"üåø Evaluating Disease Detection Model (CNN)‚Ä¶\")\n",
    "\n",
    "# 1) Load your trained CNN\n",
    "model_disease = load_model(\"../models/disease_cnn.h5\")\n",
    "\n",
    "# 2) Define the correct directory\n",
    "#   - Notebook is at src/app/testing/\n",
    "#   - Augmented images are at notebooks/data/Plant_leave_diseases_dataset_with_augmentation/\n",
    "test_dir = \"../../../notebooks/data/Plant_leave_diseases_dataset_with_augmentation\"\n",
    "\n",
    "# 3) Setup generator & evaluate\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(224, 224),   # same as your training\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",      # use the 20% split created by validation_split\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "loss, acc = model_disease.evaluate(test_generator, verbose=1)\n",
    "print(f\"üåø Disease Detection Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Market Price Prediction (optional)\n",
    "print(\"üìà Market Dashboard Data Check‚Ä¶\\n\")\n",
    "\n",
    "# Load all three cleaned tables\n",
    "area       = pd.read_csv(\"../../../market_price/data/area.csv\")\n",
    "prices     = pd.read_csv(\"../../../market_price/data/prices.csv\")\n",
    "production = pd.read_csv(\"../../../market_price/data/production.csv\")\n",
    "\n",
    "# 1) Show their heads\n",
    "print(\"‚ñ∂Ô∏è area.csv (first 5 rows):\")\n",
    "print(area.head(), \"\\n\")\n",
    "\n",
    "print(\"‚ñ∂Ô∏è prices.csv (first 5 rows):\")\n",
    "print(prices.head(), \"\\n\")\n",
    "\n",
    "print(\"‚ñ∂Ô∏è production.csv (first 5 rows):\")\n",
    "print(production.head(), \"\\n\")\n",
    "\n",
    "# 2) Basic sanity checks\n",
    "print(\"‚ñ∂Ô∏è area.csv columns:\", area.columns.tolist())\n",
    "print(\"‚ñ∂Ô∏è prices.csv columns:\", prices.columns.tolist())\n",
    "print(\"‚ñ∂Ô∏è production.csv columns:\", production.columns.tolist(), \"\\n\")\n",
    "\n",
    "# 3) Price summary\n",
    "if \"modal_price\" in prices.columns:\n",
    "    print(\"‚ñ∂Ô∏è modal_price stats:\\n\", prices[\"modal_price\"].describe(), \"\\n\")\n",
    "else:\n",
    "    # If your prices file uses a different column name, print that one\n",
    "    price_cols = [c for c in prices.columns if \"price\" in c.lower()]\n",
    "    print(f\"‚ñ∂Ô∏è Found price columns: {price_cols}\")\n",
    "    for col in price_cols:\n",
    "        print(f\"{col} stats:\\n\", prices[col].describe(), \"\\n\")\n",
    "\n",
    "# 4) Unique commodities & markets for the sidebar\n",
    "print(\"‚ñ∂Ô∏è Unique commodities:\", prices[\"commodity_name\"].unique())\n",
    "print(\"‚ñ∂Ô∏è Unique markets:\", prices[\"market_name\"].unique())\n",
    "\n",
    "print(\"\\n‚úÖ Market data looks good! Your Streamlit dashboard should be able to load these files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786fe07-9855-4201-a9c1-590ef12d1089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
